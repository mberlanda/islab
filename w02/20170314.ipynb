{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incontro ISLAB 2017-03-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Retrieval\n",
    "\n",
    "La necessità di avere uno spazio metrico è dovuta alla possibilità che ne consegue di verificare la similarità.\n",
    "In questo modo possiamo fare retrieval dei documenti una volta sviluppato il modello.\n",
    "\n",
    "Una volta definito il modello, dobbiamo preoccuparci di implementarlo:\n",
    "\n",
    "- in maniera efficiente\n",
    "- in modo scalabile\n",
    "\n",
    "Attraverso i sistemi di information retrieval booleano verranno introdotti i concetti fondamentali.\n",
    "\n",
    "I tre obiettivi dell'information retrieval sono:\n",
    "\n",
    "- searching\n",
    "- classification\n",
    "- data analysis\n",
    "\n",
    "Matrice termine di documento (**index matrix**), es.\n",
    "\n",
    "docID | id_tag_1 | id_tag_2 | id_tag_3\n",
    "------|----------|----------|---------\n",
    "123   |    1     |   0      |   0\n",
    "345   |    0     |   1      |   0\n",
    "\n",
    "I vantaggi di una forma di questo tipo sono:\n",
    "\n",
    "- facilità nel fare query: e.g. testi delle canzoni taggate peace AND love AND NOT war\n",
    "    - sono simili i documenti che rispondono alle stesse query\n",
    "- abbiamo  documenti espressi intermini di terminologia e la terminologia in termini di documenti\n",
    "    - in uno schema relazionale avrei un problema di dimensioni (ad ogni documento aggiungo colonne)\n",
    "    - la matrice è molto sparsa (molte celle con val 0)\n",
    "        - la varietà è data da una questione lessicale (nel nostro caso, non è eccessivamente sparsa perché i tag sono forniti da clarifai)\n",
    "    \n",
    "#### Inverted index:\n",
    "\n",
    "given 0,D,S as the number of token **occurences**, the **size of dictionary** (e.g. number of unique tokens/tags), and the **size of corpus** (e.g. number of documents), respectively, the **sparseness** _S_ of a corpus can be calculated as:\n",
    "\n",
    "\n",
    "$$ S = \\frac {O} {D*S} $$\n",
    "\n",
    "\n",
    "\n",
    "corpus | O | D | S | _S_\n",
    "--------|---|---|---|---\n",
    "gozzano | 17597 | 5189 | 117 | 0.028985\n",
    "songs | 261273 | 22367 | 4311 | 0.002710\n",
    "\n",
    "\n",
    "La varietà lessicale della lingua non è infinità, quindi la _sparseness_ non crescerà linearmente.\n",
    "\n",
    "Per non salvarsi tutti gli 1, si utilizza l'inverted index\n",
    "\n",
    "Dictionary | Posting\n",
    "------|----------\n",
    "123   |    1 23 ..    \n",
    "345   |    0 45 ..   \n",
    "\n",
    "\n",
    "```js\n",
    "{\n",
    "    \"token\": \"love\",\n",
    "    \"posting\": [123, 456, 789, ...]\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Pro:\n",
    "\n",
    "- la cardinalità è pari al dizionario\n",
    "- indice primario sul token (facilità di accesso)\n",
    "- usa btree per l'accesso \n",
    "    - consente di avere un tempo di accesso dei dati ordinati più efficiente. Consiste in un albero balanced: ad ogni nodo ho sempre lo stesso numero di elementi. Il campo di ricerca _O(k)_ dove k è la dimensione di ogni livello di nodi ). Se uno può scegliere, tende a farlo binario per ragioni di bilanciamento ma è strettamente legato all'allocazione della memoria.\n",
    "\n",
    "```js\n",
    "invertedindex.find({\"token\": \"love\"})\n",
    "```\n",
    "\n",
    "Contro:\n",
    "\n",
    "- indicizzare è sempre costoso: dipende se si vuole pagare in fase di acquisizione o in fase di query\n",
    "- limitatamente adottabile su un relazionale\n",
    "- la dimensione orizzontale può crescere ad libitum\n",
    "- non sono facilmente distribuibili\n",
    "\n",
    "#### DB Storage: entry as tuple\n",
    "\n",
    "```js\n",
    "{\n",
    "  \"token\": \"love\",\n",
    "  \"posting\": 598\n",
    "},\n",
    "{\n",
    "  \"token\": \"love\",\n",
    "  \"posting\": 789\n",
    "},\n",
    "```\n",
    "\n",
    "Pro:\n",
    "- la dimensione orizzontale è fissa (quasi relazionale)\n",
    "- costa pochissimo aggiunta/rimozione/aggiornamento degli elementi\n",
    "- sort dei posting al query time\n",
    "\n",
    "Contro:\n",
    "- la cardinalità cresce notevolmente\n",
    "- sort dei posting potrebbe essere inefficiente (richiede un secondary index importante)\n",
    "\n",
    "```js\n",
    "invertedindex.find({\"token\": \"love\"}).sort({\"posting\":1})\n",
    "```\n",
    "\n",
    "Indici primari sparsi: costruiti sulle chiavi primarie dei database. \n",
    " - sparso: Un campo ordinato su disco. Essendo ordinati, mi basta memorizzarne uno solo per capire quale blocco di disco devo caricare in memoria\n",
    "Indice secondario: solo su token -> non è ordinato e non è univoco\n",
    "\n",
    "\n",
    "Una index matrix booleana non permette di capire quanto sia significativo un tag rispetto a una risorsa.\n",
    "Per indicare la significatività di un token posso adattare la mia struttura, eg.\n",
    "\n",
    "```js\n",
    "{\n",
    "   \"token\": \"love\",\n",
    "   \"posting\": 599,\n",
    "   \"occurences\": 3,\n",
    "   \"doc_len\": 232\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "term frequency| example\n",
    "---|---\n",
    "binary | 0,1\n",
    "row frequency | o(t,d) of t in d\n",
    "log frequency | 1 + log o(t,d)\n",
    "normalized frequency | o(t,d) / abs(d)\n",
    "log normalized frequency | log (1 + o(t,d) / abs(d) )\n",
    "double normalized frequency | K + (1-K) o(t,d) / max[t' in d] o(t',d)\n",
    "\n",
    "\n",
    "\n",
    "occurencies per token in document d: o(t, d)\n",
    "\n",
    "document frequency permette di vedere quanto è diffuso un token.\n",
    "di solito si considera la inverse document frequency: n docs / docs containing t\n",
    "N +1 / n + 1\n",
    "\n",
    "più è alto l'IDF, maggiore è la significatività dei termini\n",
    "\n",
    "al crescere del numero di occorrenze, la crescita cumulativa dei token è un ramo di iperbole crescente\n",
    "solitamente le parole con un IDF alto hanno un numero di occrenze minori\n",
    "\n",
    "L'intersezione è più efficace da determinare in base alla dimensione delle posting list\n",
    "\n",
    "Come si valuta un sistema di information retrieval:\n",
    "- restituire risultati giusti (precision P)\n",
    "- restituire tutti i risultati (recall R)\n",
    "\n",
    "$$ P = \\frac{\\left | R\\bigcap  E\\right |}{\\left | R \\right |} $$\n",
    "$$ R = \\frac{\\left | R\\bigcap  E\\right |}{\\left | E \\right |} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "docs_len = [('d671')]\n",
    "docs = [x[0] for x in docs_len]\n",
    "words = []\n",
    "M = np.array()\n",
    "# transpose M.T\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
